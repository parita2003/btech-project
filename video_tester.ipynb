{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open shape_predictor_68_face_landmarks.dat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load pre-trained models for face and landmarks\u001b[39;00m\n\u001b[0;32m      9\u001b[0m face_detector \u001b[38;5;241m=\u001b[39m dlib\u001b[38;5;241m.\u001b[39mget_frontal_face_detector()\n\u001b[1;32m---> 10\u001b[0m landmark_predictor \u001b[38;5;241m=\u001b[39m \u001b[43mdlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshape_predictor_68_face_landmarks.dat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_video\u001b[39m(video_path, output_heatmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheatmap.png\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Open the video\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(video_path)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open shape_predictor_68_face_landmarks.dat"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import kde\n",
    "\n",
    "# Load pre-trained models for face and landmarks\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "landmark_predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "def process_video(video_path, output_heatmap=\"heatmap.png\"):\n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    gaze_points = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert to grayscale for processing\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = face_detector(gray_frame)\n",
    "        for face in faces:\n",
    "            # Get facial landmarks\n",
    "            landmarks = landmark_predictor(gray_frame, face)\n",
    "            left_eye = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(36, 42)]\n",
    "            right_eye = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(42, 48)]\n",
    "\n",
    "            # Compute the center of both eyes\n",
    "            left_eye_center = np.mean(left_eye, axis=0).astype(int)\n",
    "            right_eye_center = np.mean(right_eye, axis=0).astype(int)\n",
    "\n",
    "            # Append gaze points\n",
    "            gaze_points.append(left_eye_center)\n",
    "            gaze_points.append(right_eye_center)\n",
    "\n",
    "            # Draw eyes on the frame (for visualization, optional)\n",
    "            cv2.circle(frame, tuple(left_eye_center), 3, (255, 0, 0), -1)\n",
    "            cv2.circle(frame, tuple(right_eye_center), 3, (255, 0, 0), -1)\n",
    "\n",
    "        # Display the frame (optional, for debugging)\n",
    "        cv2.imshow(\"Processing Video\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Generate Heatmap\n",
    "    generate_heatmap(gaze_points, output_heatmap)\n",
    "\n",
    "def generate_heatmap(gaze_points, output_file):\n",
    "    # Convert gaze points to x and y coordinates\n",
    "    x_coords = [point[0] for point in gaze_points]\n",
    "    y_coords = [point[1] for point in gaze_points]\n",
    "\n",
    "    # Create a heatmap using seaborn\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(x=x_coords, y=y_coords, cmap=\"Reds\", shade=True, bw_adjust=0.5)\n",
    "    plt.title(\"Eye Gaze Heatmap\")\n",
    "\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to match image coordinates\n",
    "    plt.savefig(output_file)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Heatmap sa|ved as {output_file}\")\n",
    "\n",
    "# Example Usage\n",
    "process_video(\"trial.mp4\", output_heatmap=\"eye_gaze_heatmap.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
